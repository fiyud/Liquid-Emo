{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FAUqEGOtatCT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# import dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# import pad sequence\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "sys.path.append('D:/NCKH.2025-2026/profHuong/Emotional-Vietnamese-Speech-Based-Depression-Diagnosis-Using-Dynamic-Attention-Mechanism')\n",
    "#from common import CBAM\n",
    "avarage = 'micro'\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pgqN_6wfatCZ"
   },
   "outputs": [],
   "source": [
    "class Dual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dual, self).__init__()\n",
    "\n",
    "        # self.feature_extractor1 = nn.Sequential(\n",
    "        #     # 1st Conv Layer + BatchNorm + ReLU + Pooling\n",
    "        #     nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "\n",
    "        #     # 2nd Conv Layer + BatchNorm + ReLU + Pooling\n",
    "        #     nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "\n",
    "        #     # 3rd Conv Layer + BatchNorm + ReLU + Pooling\n",
    "        #     nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "\n",
    "        #     # 4th Conv Layer + BatchNorm + ReLU + Pooling\n",
    "        #     nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        # )\n",
    "\n",
    "        # self.lstm = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
    "        # # out put lstm (batch_size, seq_len, hidden_size) (batch_size, 1, 256)\n",
    "        # self.fc1 = nn.Linear(256, 5)\n",
    "\n",
    "        self.feature_extractor2 = nn.Sequential(\n",
    "            # 1st Conv Layer + BatchNorm + ReLU + Pooling\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=1),  # (128, 251) -> (128, 251, 64)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),  # (128, 251, 64) -> (64, 125, 64)\n",
    "\n",
    "            # 2nd Conv Layer + BatchNorm + ReLU + Pooling\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=1),  # (64, 125, 64) -> (64, 125, 64)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 4), stride=(4, 4)),  # (64, 125, 64) -> (16, 31, 64)\n",
    "\n",
    "            # 3rd Conv Layer + BatchNorm + ReLU + Pooling\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=1),  # (16, 31, 64) -> (16, 31, 128)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 4), stride=(4, 4)),  # (16, 31, 128) -> (4, 7, 128)\n",
    "\n",
    "            # 4th Conv Layer + BatchNorm + ReLU + Pooling\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=1),  # (4, 7, 128) -> (4, 7, 128)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(4, 4), stride=(4, 4))  # (4, 7, 128) -> (1, 1, 128)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),  # 1*1*128 -> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 7),  # 256 -> 5\n",
    "        )\n",
    "\n",
    "        # self.truefc = nn.Softmax(dim=1)\n",
    "        self.gru = nn.GRU(input_size=128, hidden_size=256, bidirectional=False, batch_first=True)\n",
    "        self.fc3 = nn.Linear(7, 7)\n",
    "\n",
    "\n",
    "    def forward(self, mfcc):\n",
    "        # wave_form = self.feature_extractor1(wave_form)  # Pass through the sequential feature extractor\n",
    "\n",
    "        # # LSTM expects input of shape (batch_size, seq_len, input_size)\n",
    "        # wave_form = wave_form.permute(0, 2, 1)  # Reshape to (batch_size, seq_len, input_size)\n",
    "        # wave_form, _ = self.lstm(wave_form)\n",
    "\n",
    "        # wave_form = wave_form[:, -1, :]\n",
    "\n",
    "        # wave_form = self.fc1(wave_form)\n",
    "\n",
    "        mfcc = self.feature_extractor2(mfcc)\n",
    "        #mfcc = self.cbam(mfcc)\n",
    "        mfcc = mfcc.squeeze().unsqueeze(1)\n",
    "\n",
    "        mfcc,_ = self.gru(mfcc)\n",
    "        mfcc = self.fc2(mfcc)\n",
    "        # x = torch.cat((wave_form, mfcc), dim=1)\n",
    "\n",
    "        mfcc = self.fc3(mfcc)\n",
    "\n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxCFN8YRatCa"
   },
   "outputs": [],
   "source": [
    "n_mfcc = 128\n",
    "window_size = 2048\n",
    "strides = 512\n",
    "window_size_stft = 1024\n",
    "window = np.hanning(window_size_stft)\n",
    "\n",
    "emotion_map = {\n",
    "    'W': 0,  # Anger\n",
    "    'L': 1,  # Boredom\n",
    "    'A': 2,  # Anxiety\n",
    "    'F': 3,  # Happiness\n",
    "    'T': 4,  # Sadness\n",
    "    'E': 5,  # Disgust\n",
    "    'N': 6   # Neutral\n",
    "}\n",
    "\n",
    "def load_emodata(link, sr = 16000, duration = 5):\n",
    "    # Load the audio file\n",
    "    wave_form, _ = librosa.load(path=link, sr=sr)\n",
    "    # label = father folder name\n",
    "    filename = os.path.basename(link)\n",
    "    emo_code = filename[5] \n",
    "    labels = emotion_map.get(emo_code, -1) \n",
    "\n",
    "    if len(wave_form) < sr * duration:\n",
    "        # zero pad the audio if its less than 5 seconds\n",
    "        wave_form = np.pad(wave_form, (0, sr * duration - len(wave_form)), 'symmetric')\n",
    "        mfcc1 = librosa.feature.mfcc(y=wave_form, sr=8000, n_mfcc=n_mfcc, n_fft=window_size, hop_length=strides)\n",
    "        # stft1 = librosa.core.spectrum.stft(wave_form, n_fft=window_size_stft, hop_length=256, window=window)\n",
    "        # spect1 = 2 * np.abs(stft1) / np.sum(window)\n",
    "        return np.array([mfcc1]), np.array([labels])\n",
    "\n",
    "    elif len(wave_form) == sr * duration:\n",
    "        mfcc2 = librosa.feature.mfcc(y=wave_form, sr=8000, n_mfcc=n_mfcc, n_fft=window_size, hop_length=strides)\n",
    "        # stft2 = librosa.core.spectrum.stft(wave_form, n_fft=window_size_stft, hop_length=256, window=window)\n",
    "        # spect2 = 2 * np.abs(stft2) / np.sum(window)\n",
    "        # return the audio as it is\n",
    "        return np.array([mfcc2]), np.array([labels])\n",
    "\n",
    "\n",
    "    else:\n",
    "        wave_segments = []\n",
    "        _labels = [labels] * (len(wave_form) // (sr * duration) + 1)\n",
    "        for i in range(0, len(wave_form), sr * duration):\n",
    "            wave_segments.append(wave_form[i:i + sr * duration])\n",
    "\n",
    "        # If the last segment is less than 5 seconds, then pad it with the last 5 seconds of the second last segment\n",
    "        len_wave_segments_last = len(wave_segments[-1])\n",
    "        padding = sr * duration - len_wave_segments_last\n",
    "        temp = np.append(wave_segments[-2][sr * duration - padding:], wave_segments[-1])\n",
    "        wave_segments[-1] = temp\n",
    "\n",
    "        mfcc_seg = librosa.feature.mfcc(y=np.array(wave_segments), sr=8000, n_mfcc=n_mfcc, n_fft=window_size, hop_length=strides)\n",
    "        # stft_seg = librosa.core.spectrum.stft(wave_segments, n_fft=window_size_stft, hop_length=256, window=window)\n",
    "        # spect_seg = 2 * np.abs(stft_seg) / np.sum(window)\n",
    "\n",
    "        return np.array(mfcc_seg) , np.array(_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7USLCOQUatCa"
   },
   "outputs": [],
   "source": [
    "data_folder = \"c:/Users/GIGABYTE/Downloads/archive/wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dAYz1TdvatCa"
   },
   "outputs": [],
   "source": [
    "def load_data(data_folder):\n",
    "    # waves = []\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                link = os.path.join(root, file)\n",
    "                mfcc, label = load_emodata(link)\n",
    "\n",
    "                # waves.extend(wave)\n",
    "                mfccs.extend(mfcc)\n",
    "                labels.extend(label)\n",
    "\n",
    "    return np.array(mfccs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_fKEDR32atCb"
   },
   "outputs": [],
   "source": [
    "mfccs, labels = load_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1724873769738,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "4Nq4YNb6atCb",
    "outputId": "459c96c0-5d51-42d6-b33f-660c457be2a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 560)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mfccs), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9exxxBmPatCc"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-pXufmmlatCd"
   },
   "outputs": [],
   "source": [
    "class EmoDataset(Dataset):\n",
    "    def __init__(self, mfccs, labels):\n",
    "\n",
    "        self.mfccs = mfccs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfccs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.mfccs[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "nHKlEstwatCd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZnNwp0bQatCd"
   },
   "outputs": [],
   "source": [
    "EMO_CLASSES = {label: i for i, label in enumerate(np.unique(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1724873769739,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "U-O3eW7watCd",
    "outputId": "bf6f8503-0fb8-4917-d6ef-3dc8c8d599f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): 0,\n",
       " np.int64(1): 1,\n",
       " np.int64(2): 2,\n",
       " np.int64(3): 3,\n",
       " np.int64(4): 4,\n",
       " np.int64(5): 5,\n",
       " np.int64(6): 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMO_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1724873769739,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "_uVWo4-_atCd",
    "outputId": "665c9891-5c5f-449d-dd3c-e8a56aa625c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  Counter({0: 102, 1: 65, 6: 64, 4: 63, 3: 56, 2: 55, 5: 43})\n",
      "Test data:  Counter({0: 26, 1: 16, 4: 16, 3: 15, 6: 15, 2: 14, 5: 10})\n",
      "Train data:  Counter({0: 102, 1: 64, 6: 63, 4: 63, 3: 57, 2: 56, 5: 43})\n",
      "Test data:  Counter({0: 26, 1: 17, 6: 16, 4: 16, 3: 14, 2: 13, 5: 10})\n",
      "Train data:  Counter({0: 102, 1: 65, 4: 64, 6: 63, 3: 57, 2: 55, 5: 42})\n",
      "Test data:  Counter({0: 26, 6: 16, 1: 16, 4: 15, 3: 14, 2: 14, 5: 11})\n",
      "Train data:  Counter({0: 103, 1: 65, 6: 63, 4: 63, 3: 57, 2: 55, 5: 42})\n",
      "Test data:  Counter({0: 25, 6: 16, 1: 16, 4: 16, 2: 14, 3: 14, 5: 11})\n",
      "Train data:  Counter({0: 103, 1: 65, 6: 63, 4: 63, 3: 57, 2: 55, 5: 42})\n",
      "Test data:  Counter({0: 25, 4: 16, 6: 16, 1: 16, 2: 14, 3: 14, 5: 11})\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_idx, test_idx) in enumerate(skf.split(mfccs, labels)):\n",
    "\n",
    "    # wave_train, wave_test = waves[train_idx], waves[test_idx]\n",
    "    mfcc_train, mfcc_test = mfccs[train_idx], mfccs[test_idx]\n",
    "    train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    train_labels = [EMO_CLASSES[label] for label in train_labels]\n",
    "    test_labels = [EMO_CLASSES[label] for label in test_labels]\n",
    "\n",
    "\n",
    "    train_dataset = EmoDataset(mfcc_train, train_labels)\n",
    "    test_dataset = EmoDataset(mfcc_test, test_labels)\n",
    "\n",
    "    print(\"Train data: \", Counter(train_labels))\n",
    "    print(\"Test data: \", Counter(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "i5bOHKixatCd"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1U0uqadXatCe"
   },
   "outputs": [],
   "source": [
    "EMO_CLASSES = {label: i for i, label in enumerate(set(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "GXQzUYlTatCe"
   },
   "outputs": [],
   "source": [
    "acc_kfold = []\n",
    "f1_kfold = []\n",
    "recall_kfold = []\n",
    "precision_kfold = []\n",
    "data_kfold = []\n",
    "labels_preds_kfold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108981,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "Z4x_I9yfatCe",
    "outputId": "698e45ea-ba92-4db5-cc7e-b9361c7068f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:  0 Epoch:  0 Train loss:  1.7537360021046229\n",
      "K-Fold: 0, Epoch: 0, Accuracy: 0.33035714285714285, Recall: 0.33035714285714285, F1: 0.33035714285714285, Precision: 0.33035714285714285\n",
      "K-Fold:  0 Epoch:  1 Train loss:  1.4095699020794459\n",
      "K-Fold: 0, Epoch: 1, Accuracy: 0.30357142857142855, Recall: 0.30357142857142855, F1: 0.30357142857142855, Precision: 0.30357142857142855\n",
      "K-Fold:  0 Epoch:  2 Train loss:  1.355669115270887\n",
      "K-Fold: 0, Epoch: 2, Accuracy: 0.39285714285714285, Recall: 0.39285714285714285, F1: 0.39285714285714285, Precision: 0.39285714285714285\n",
      "K-Fold:  0 Epoch:  3 Train loss:  1.1674457149846214\n",
      "K-Fold: 0, Epoch: 3, Accuracy: 0.375, Recall: 0.375, F1: 0.375, Precision: 0.375\n",
      "K-Fold:  0 Epoch:  4 Train loss:  1.01793800507273\n",
      "K-Fold: 0, Epoch: 4, Accuracy: 0.48214285714285715, Recall: 0.48214285714285715, F1: 0.48214285714285715, Precision: 0.48214285714285715\n",
      "K-Fold:  0 Epoch:  5 Train loss:  0.8872150012425014\n",
      "K-Fold: 0, Epoch: 5, Accuracy: 0.5446428571428571, Recall: 0.5446428571428571, F1: 0.5446428571428571, Precision: 0.5446428571428571\n",
      "K-Fold:  0 Epoch:  6 Train loss:  0.8431432098150253\n",
      "K-Fold: 0, Epoch: 6, Accuracy: 0.5089285714285714, Recall: 0.5089285714285714, F1: 0.5089285714285714, Precision: 0.5089285714285714\n",
      "K-Fold:  0 Epoch:  7 Train loss:  0.7254437633923122\n",
      "K-Fold: 0, Epoch: 7, Accuracy: 0.25, Recall: 0.25, F1: 0.25, Precision: 0.25\n",
      "K-Fold:  0 Epoch:  8 Train loss:  0.6003940148012978\n",
      "K-Fold: 0, Epoch: 8, Accuracy: 0.6339285714285714, Recall: 0.6339285714285714, F1: 0.6339285714285714, Precision: 0.6339285714285714\n",
      "K-Fold:  0 Epoch:  9 Train loss:  0.5494276476757867\n",
      "K-Fold: 0, Epoch: 9, Accuracy: 0.2857142857142857, Recall: 0.2857142857142857, F1: 0.2857142857142857, Precision: 0.2857142857142857\n",
      "K-Fold:  0 Epoch:  10 Train loss:  0.6279914400407246\n",
      "K-Fold: 0, Epoch: 10, Accuracy: 0.4017857142857143, Recall: 0.4017857142857143, F1: 0.4017857142857143, Precision: 0.4017857142857143\n",
      "K-Fold:  0 Epoch:  11 Train loss:  0.6247697398066521\n",
      "K-Fold: 0, Epoch: 11, Accuracy: 0.4732142857142857, Recall: 0.4732142857142857, F1: 0.4732142857142857, Precision: 0.4732142857142857\n",
      "K-Fold:  0 Epoch:  12 Train loss:  0.5163307849849973\n",
      "K-Fold: 0, Epoch: 12, Accuracy: 0.5178571428571429, Recall: 0.5178571428571429, F1: 0.5178571428571429, Precision: 0.5178571428571429\n",
      "K-Fold:  0 Epoch:  13 Train loss:  0.3476450943521091\n",
      "K-Fold: 0, Epoch: 13, Accuracy: 0.5535714285714286, Recall: 0.5535714285714286, F1: 0.5535714285714286, Precision: 0.5535714285714286\n",
      "K-Fold:  0 Epoch:  14 Train loss:  0.23610953773771012\n",
      "K-Fold: 0, Epoch: 14, Accuracy: 0.5982142857142857, Recall: 0.5982142857142857, F1: 0.5982142857142857, Precision: 0.5982142857142857\n",
      "K-Fold:  0 Epoch:  15 Train loss:  0.2943135473345007\n",
      "K-Fold: 0, Epoch: 15, Accuracy: 0.49107142857142855, Recall: 0.49107142857142855, F1: 0.49107142857142855, Precision: 0.49107142857142855\n",
      "K-Fold:  0 Epoch:  16 Train loss:  0.25996422129017965\n",
      "K-Fold: 0, Epoch: 16, Accuracy: 0.6339285714285714, Recall: 0.6339285714285714, F1: 0.6339285714285714, Precision: 0.6339285714285714\n",
      "K-Fold:  0 Epoch:  17 Train loss:  0.23395143928272383\n",
      "K-Fold: 0, Epoch: 17, Accuracy: 0.6160714285714286, Recall: 0.6160714285714286, F1: 0.6160714285714286, Precision: 0.6160714285714286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m label = label.to(device)\n\u001b[32m     39\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m loss = loss_fn(output, label)\n\u001b[32m     43\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mDual.forward\u001b[39m\u001b[34m(self, mfcc)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, mfcc):\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# wave_form = self.feature_extractor1(wave_form)  # Pass through the sequential feature extractor\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# wave_form = self.fc1(wave_form)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     mfcc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m#mfcc = self.cbam(mfcc)\u001b[39;00m\n\u001b[32m     87\u001b[39m     mfcc = mfcc.squeeze().unsqueeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for idx, (train_idx, test_idx) in enumerate(skf.split(mfccs, labels)):\n",
    "\n",
    "    mfcc_train, mfcc_test = mfccs[train_idx], mfccs[test_idx]\n",
    "    train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    train_labels = [EMO_CLASSES[label] for label in train_labels]\n",
    "    test_labels = [EMO_CLASSES[label] for label in test_labels]\n",
    "\n",
    "\n",
    "    train_dataset = EmoDataset(mfcc_train, train_labels)\n",
    "    test_dataset = EmoDataset(mfcc_test, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Dual()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "    best_recall = 0\n",
    "    best_precision = 0\n",
    "\n",
    "    acc = []\n",
    "    f1 = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    best_labels_preds = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tt_loss = 0\n",
    "        model.train()\n",
    "        for mfcc, label in train_loader:\n",
    "\n",
    "            mfcc = mfcc.unsqueeze(1).to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(mfcc)\n",
    "\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tt_loss += loss.item()\n",
    "\n",
    "        print(\"K-Fold: \", idx, \"Epoch: \", epoch, \"Train loss: \", tt_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "\n",
    "            for mfcc, label in test_loader:\n",
    "\n",
    "                mfcc = mfcc.unsqueeze(1).to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                output = model(mfcc)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "\n",
    "                all_labels.extend(label.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            validation_acc = accuracy_score(all_labels, all_preds)\n",
    "            recall_val = recall_score(all_labels, all_preds, average=\"micro\")\n",
    "            f1_val = f1_score(all_labels, all_preds, average=\"micro\")\n",
    "            precision_val = precision_score(all_labels, all_preds, average=\"micro\")\n",
    "\n",
    "            acc.append(validation_acc)\n",
    "            f1.append(f1_val)\n",
    "            recall.append(recall_val)\n",
    "            precision.append(precision_val)\n",
    "\n",
    "\n",
    "            if validation_acc > best_acc:\n",
    "                best_acc = validation_acc\n",
    "                best_recall = recall_val\n",
    "                best_f1 = f1_val\n",
    "                best_precision = precision_val\n",
    "                best_labels_preds = [all_labels, all_preds]\n",
    "\n",
    "                # torch.save(model.state_dict(), f\"best_model_{idx}.pth\")\n",
    "\n",
    "            print(f\"K-Fold: {idx}, Epoch: {epoch}, Accuracy: {validation_acc}, Recall: {recall_val}, F1: {f1_val}, Precision: {precision_val}\")\n",
    "\n",
    "    data_kfold.append([acc, f1, recall, precision])\n",
    "\n",
    "    acc_kfold.append(best_acc)\n",
    "    f1_kfold.append(best_f1)\n",
    "    recall_kfold.append(best_recall)\n",
    "    precision_kfold.append(best_precision)\n",
    "    labels_preds_kfold.append(best_labels_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "iE1IjORJatCe",
    "outputId": "49596992-38dc-423c-b859-1c71547ae8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "AyFILjk9atCf",
    "outputId": "c27fcd6a-9025-4e39-86c2-7c786250dac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_preds_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "xjIDNb4tatCf"
   },
   "outputs": [],
   "source": [
    "def print_classification_report(labels_preds_kfold):\n",
    "    for idx, data in enumerate(labels_preds_kfold):\n",
    "        print(f\"K-Fold: {idx}\")\n",
    "        print(classification_report(data[0], data[1], target_names=EMO_CLASSES.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dPV65lfIatCf"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(data_kfold):\n",
    "    num_folds = len(data_kfold)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    for idx, data in enumerate(data_kfold):\n",
    "        acc, f1, recall, precision = data\n",
    "        plt.subplot(1, num_folds, idx + 1)\n",
    "        plt.plot(acc, label='Accuracy')\n",
    "        plt.plot(recall, label='Recall')\n",
    "        plt.plot(f1, label='F1')\n",
    "        plt.plot(precision, label='Precision')\n",
    "        plt.title(f\"K-Fold {idx + 1}\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Metrics')\n",
    "        plt.ylim(0.0, 1.0)  # Set y-axis range from 0.0 to 1.0\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()  # Adjust subplots to fit into figure area\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "ovpvOeOtatCf",
    "outputId": "f323e381-a1a5-4050-819d-c4732d923cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "KP86r3RzatCf",
    "outputId": "23280adf-8654-4b3a-9962-c0b7dec1058c"
   },
   "outputs": [],
   "source": [
    "np.mean(acc_kfold),np.mean(f1_kfold),np.mean(precision_kfold),np.mean(f1_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1724873878711,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "vP95sMFKatCf",
    "outputId": "2f726521-0851-41a0-dd84-38b81e425d07"
   },
   "outputs": [],
   "source": [
    "print_classification_report(labels_preds_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf6tl6lsatCf"
   },
   "outputs": [],
   "source": [
    "# average classification report\n",
    "def average_classification_report(labels_preds_kfold):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for data in labels_preds_kfold:\n",
    "        all_labels.extend(data[0])\n",
    "        all_preds.extend(data[1])\n",
    "    print(classification_report(all_labels, all_preds, target_names=EMO_CLASSES.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1724873878712,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "nZfhCGXvatCf",
    "outputId": "803ab22c-54bf-4880-9cf8-75a9d8ce7217"
   },
   "outputs": [],
   "source": [
    "average_classification_report(labels_preds_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gn7XU9jatCg"
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(labels_preds_kfold):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for data in labels_preds_kfold:\n",
    "        all_labels.extend(data[0])\n",
    "        all_preds.extend(data[1])\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=EMO_CLASSES.keys(), yticklabels=EMO_CLASSES.keys())\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1724873879739,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "MGDIQtLpatCg",
    "outputId": "0c719a5f-d32a-47db-c7d8-87dc23250dc4"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(labels_preds_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhNr4WMWatCg"
   },
   "outputs": [],
   "source": [
    "def compute_ua_wa(labels_preds_kfold):\n",
    "    true_labels = np.array([])\n",
    "    predicted_labels = np.array([])\n",
    "\n",
    "    # Gộp tất cả nhãn thực và nhãn dự đoán từ các fold\n",
    "    for data in labels_preds_kfold:\n",
    "        true_labels = np.append(true_labels, data[0])\n",
    "        predicted_labels = np.append(predicted_labels, data[1])\n",
    "\n",
    "    # Tính UA (Unweighted Accuracy)\n",
    "    ua = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Tính WA (Weighted Accuracy)\n",
    "    wa = []\n",
    "    for label in np.unique(true_labels):\n",
    "        i_true = true_labels[true_labels == label]\n",
    "        i_predicted = predicted_labels[true_labels == label]\n",
    "\n",
    "        wa.append(np.sum(i_true == i_predicted) / len(i_true))\n",
    "    wa = np.mean(wa)\n",
    "    return ua, wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1724873879739,
     "user": {
      "displayName": "Nguyễn Đức Quang Anh",
      "userId": "05768917261476937201"
     },
     "user_tz": -420
    },
    "id": "gMqdLLOFatCg",
    "outputId": "78c38944-c00d-40b1-f60c-4f27fa772b35"
   },
   "outputs": [],
   "source": [
    "ua, wa = compute_ua_wa(labels_preds_kfold)\n",
    "print(f\"Unweighted Accuracy: {ua}, Weighted Accuracy: {wa}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
